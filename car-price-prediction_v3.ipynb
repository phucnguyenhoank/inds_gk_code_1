{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vấn đề, tầm quan trọng, mục tiêu dự án."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vấn đề: Dự đoán giá xe dựa trên các thuộc tính như tuổi xe, loại nhiên liệu, km đã đi, v.v., và phân cụm để hiểu phân khúc thị trường.\n",
    "\n",
    "- Giải thích tầm quan trọng: Thị trường xe cũ ở Ấn Độ phát triển mạnh (khoảng 3,4 triệu xe giao dịch mỗi năm theo IJERT), ảnh hưởng bởi chính sách (BS-VI), và nhu cầu cá nhân hóa sau COVID-19.\n",
    "\n",
    "- Đặt mục tiêu: \n",
    "    - Xây dựng mô hình Random Forest để dự đoán giá xe chính xác.\n",
    "    - Khám phá các yếu tố chính ảnh hưởng đến giá."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load the Data  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df1 = pd.read_csv('raw_csv/cardekho.csv')\n",
    "raw_df2 = pd.read_csv('raw_csv/train.csv')\n",
    "raw_df3 = pd.read_csv('raw_csv/processes2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Display and Describe Attributes, Number of Records  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_df1.shape)\n",
    "raw_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_df2.shape)\n",
    "raw_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_df3.shape)\n",
    "raw_df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Standardize Column Names, Data Types, and Units  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defind the correct order of columns\n",
    "correct_order = ['name', 'year', 'selling_price', 'km_driven', 'fuel', 'transmission', 'owner', 'mileage', 'engine', 'max_power', 'seats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df1 = raw_df1[(raw_df1['fuel']!='CNG') & (raw_df1['fuel']!='LPG') & (raw_df1['owner']!='Test Drive Car')]\n",
    "raw_df1['owner'] = raw_df1['owner'].str.replace(' Owner','',regex=True)\n",
    "raw_df1['name'] = raw_df1['name'].str.split().str[0]# .str.title()\n",
    "raw_df1['selling_price'] = raw_df1['selling_price'] / 100000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary ánh xạ từ tên cột cũ sang tên cột mới\n",
    "column_mapping_df1 = {\n",
    "    \"mileage(km/ltr/kg)\": \"mileage\"\n",
    "}\n",
    "raw_df1 = raw_df1.drop(columns=['seller_type'])\n",
    "raw_df1.rename(columns=column_mapping_df1, inplace=True)\n",
    "print(raw_df1.columns)\n",
    "raw_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df2 = raw_df2[raw_df2['Fuel_Type']!='Electric']\n",
    "raw_df2['Engine'] = raw_df2['Engine'].str.extract('(\\d+)')  # Lấy chỉ số trong chuỗi\n",
    "raw_df2['Power'] = raw_df2['Power'].str.extract('(\\d+)')  # Lấy chỉ số trong chuỗi\n",
    "raw_df2['Mileage'] = raw_df2['Mileage'].str.extract('(\\d+)')  # Lấy chỉ số trong chuỗi\n",
    "raw_df2 = raw_df2[~raw_df2['Mileage'].str.contains('km/kg', na=False)]\n",
    "raw_df2['Name'] = raw_df2['Name'].str.split(' ').str[0]\n",
    "raw_df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping_df2 = {\n",
    "    \"Year\": \"year\",\n",
    "    \"Kilometers_Driven\": \"km_driven\",\n",
    "    \"Fuel_Type\": \"fuel\",\n",
    "    \"Transmission\": \"transmission\",\n",
    "    \"Mileage\": \"mileage\",\n",
    "    \"Engine\": \"engine\",\n",
    "    \"Power\": \"max_power\",\n",
    "    \"Seats\": \"seats\",\n",
    "    \"Price\": \"selling_price\",\n",
    "    \"Name\": \"name\",\n",
    "    \"Owner_Type\": \"owner\"\n",
    "}\n",
    "raw_df2 = raw_df2.drop(columns=['New_Price', 'Location','Unnamed: 0'])\n",
    "raw_df2.rename(columns=column_mapping_df2, inplace=True)\n",
    "raw_df2 = raw_df2[correct_order]\n",
    "raw_df2.info()\n",
    "raw_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df3 = raw_df3[(raw_df3['fuel']!='CNG') & (raw_df3['fuel']!='LPG') & (raw_df3['owner']!='Test Drive Car')]\n",
    "raw_df3['owner'] = raw_df3['owner'].str.replace(' Owner','',regex=True)\n",
    "raw_df3['selling_price'] = raw_df3['selling_price'] / 100000.0\n",
    "print(raw_df3['fuel'].unique())\n",
    "print(raw_df3['owner'].unique())\n",
    "raw_df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping_df3 = {\n",
    "    \"max_power (in bph)\": \"max_power\",\n",
    "    \"Mileage\": \"mileage\",\n",
    "    \"Engine (CC)\": \"engine\"\n",
    "}\n",
    "raw_df3 = raw_df3.drop(columns=['seller_type', 'Mileage Unit', 'Unnamed: 0'])\n",
    "raw_df3.rename(columns=column_mapping_df3, inplace=True)\n",
    "raw_df3 = raw_df3[correct_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(df, columns, figsize=(15, 12), bins_method='sqrt'):\n",
    "    \"\"\"\n",
    "    Plot histograms for continuous columns in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        columns (list): List of column names to plot histograms for.\n",
    "        figsize (tuple): Figure size (default is (15, 12)).\n",
    "        bins_method (str): Method for calculating bins using numpy.histogram_bin_edges() (default is 'sqrt').\n",
    "\n",
    "    Returns:\n",
    "        None (Displays the plots).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    for index, col in enumerate(columns):\n",
    "        plt.subplot(2, 2, index + 1)\n",
    "        \n",
    "        # Convert column to numeric type, removing invalid values\n",
    "        data = pd.to_numeric(df[col], errors='coerce').dropna()\n",
    "        \n",
    "        # Compute bin edges using the specified method\n",
    "        bin_edges = np.histogram_bin_edges(data, bins=bins_method)\n",
    "        num_bins = len(bin_edges) - 1  # Actual number of bins\n",
    "        \n",
    "        # Plot histogram with the calculated number of bins\n",
    "        sns.histplot(data=data, bins=num_bins, color=sns.color_palette('pastel')[index], kde=True)\n",
    "        \n",
    "        plt.title(col.replace('_', ' ').capitalize(), fontsize=14, pad=10)\n",
    "        plt.xlabel(col.replace('_', ' ').capitalize(), fontsize=12)\n",
    "        plt.ylabel('Frequency', fontsize=12)\n",
    "        \n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tick_params(axis='both', labelsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_raw_columns = ['km_driven', 'mileage', 'engine', 'max_power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df1.info()\n",
    "raw_df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df2.info()\n",
    "raw_df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df3.info()\n",
    "raw_df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Merge and Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 3 datasets\n",
    "merged_df = pd.concat([raw_df1, raw_df2, raw_df3], ignore_index=True)\n",
    "\n",
    "# Export to CSV file\n",
    "saved_file_path = 'raw_csv/merged_dataset.csv'\n",
    "merged_df.to_csv(saved_file_path, index=False)\n",
    "\n",
    "# Print message\n",
    "print(f\"Merged and saved to '{saved_file_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Handle Incorrect and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load merge data\n",
    "merged_df = pd.read_csv(saved_file_path)\n",
    "print(merged_df.shape)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()\n",
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take copy from data to make processes on\n",
    "preprocessed_df = deepcopy(merged_df)\n",
    "\n",
    "# Show all types of columns in the data\n",
    "preprocessed_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check about none values in data to decide if we will make data cleaning or not\n",
    "preprocessed_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count of zero values per column:\\n\", (preprocessed_df == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling zero values\n",
    "cols_to_replace_zeros = ['mileage', 'max_power']\n",
    "preprocessed_df[cols_to_replace_zeros] = preprocessed_df[cols_to_replace_zeros].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values of float columns that are mileage, engine, seats\n",
    "column_float_imputed = ['mileage', 'engine', 'max_power']\n",
    "preprocessed_df[column_float_imputed] = preprocessed_df[column_float_imputed].fillna(preprocessed_df[column_float_imputed].mean())\n",
    "\n",
    "# Handle missing values of seats column \n",
    "preprocessed_df['seats'] = preprocessed_df['seats'].fillna(preprocessed_df['seats'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is any missing values in the dataset\n",
    "print(\"Count of Null values per column:\\n\", preprocessed_df.isnull().sum())\n",
    "print(\"Count of zero values per column:\\n\", (preprocessed_df == 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Handle textual columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all textual columns in the dataset\n",
    "textual_columns = preprocessed_df.select_dtypes(include = ['object']).columns\n",
    "preprocessed_df[textual_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label encoding textual columns\n",
    "\n",
    "# Dictionary to store the encoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Fit and transform each textual column, saving the encoders\n",
    "for col in textual_columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    preprocessed_df[col] = label_encoder.fit_transform(preprocessed_df[col])\n",
    "    label_encoders[col] = label_encoder\n",
    "\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check about if there is any extra textual columns\n",
    "preprocessed_df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_skewness(df, target_column=\"selling_price\"):\n",
    "    \"\"\"\n",
    "    Plots the skewness of numerical features in the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Preprocessed dataframe.\n",
    "        target_column (str): The target column to exclude from skewness calculation.\n",
    "    \"\"\"\n",
    "    # Remove target column\n",
    "    column_skewed = df.columns.drop(target_column)\n",
    "    \n",
    "    # Compute skewness\n",
    "    skewness = df[column_skewed].skew()\n",
    "    print(skewness)\n",
    "\n",
    "    # Plot skewness as a bar chart\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    sns.barplot(x=column_skewed, y=skewness, hue=column_skewed, palette='coolwarm')\n",
    "\n",
    "    plt.title('Skewness of Features in Dataset', fontsize=16, pad=20)\n",
    "    plt.xlabel('Features', fontsize=12)\n",
    "    plt.ylabel('Skewness', fontsize=12)\n",
    "\n",
    "    plt.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_skewness(preprocessed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle skewness of km driven columns by taking the log function for it\n",
    "preprocessed_df['km_driven'] = np.log(preprocessed_df['km_driven'] + 1)\n",
    "\n",
    "# Find skewness for km driven column after we handled it\n",
    "preprocessed_df['km_driven'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_skewness(preprocessed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.info()\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Save the preprocessed data and label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir = \"processed_data\"\n",
    "saved_processed_data_path = os.path.join(processed_data_dir, \"preprocessed_dataset.csv\")\n",
    "saved_label_encoders_path = os.path.join(processed_data_dir, \"label_encoders.sav\")\n",
    "os.makedirs(processed_data_dir, exist_ok=True)\n",
    "\n",
    "# Save preprocessed DataFrame\n",
    "preprocessed_df.to_csv(saved_processed_data_path, index=False)\n",
    "\n",
    "# Save label encoders\n",
    "joblib.dump(label_encoders, saved_label_encoders_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Statistical Analysis and Model Building on Processed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Load the Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = pd.read_csv(saved_processed_data_path)\n",
    "label_encoders = joblib.load(saved_label_encoders_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Distribution of continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(preprocessed_df, continuous_raw_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = preprocessed_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='Blues', \n",
    "            annot_kws={\"size\": 10}, linewidths=0.5, fmt=\".2f\")\n",
    "plt.title('Correlation Matrix', fontsize=20)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_with_price = correlation_matrix['selling_price'].drop('selling_price').sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=corr_with_price.index, y=corr_with_price.values, \n",
    "            hue=corr_with_price.index, palette='Blues_d')\n",
    "\n",
    "plt.title('Correlation of Features with Selling Price', fontsize=16, pad=20)\n",
    "\n",
    "plt.xlabel('Features', fontsize=12)\n",
    "plt.ylabel('Correlation Coefficient', fontsize=12)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Overview of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['name', 'fuel', 'transmission', 'owner', 'seats', 'year']\n",
    "threshold = 3.0\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "def plot_pie_chart(df, column, ax, encoders):\n",
    "    data = df[column]\n",
    "\n",
    "    if column in encoders:\n",
    "        data = encoders[column].inverse_transform(data)\n",
    "\n",
    "    value_counts = pd.Series(data).value_counts()\n",
    "    percentages = value_counts / value_counts.sum() * 100\n",
    "\n",
    "    mask = percentages < threshold\n",
    "    if mask.any():\n",
    "        other_percentage = percentages[mask].sum()\n",
    "        percentages = percentages[~mask]\n",
    "        percentages['Other'] = other_percentage\n",
    "\n",
    "    colors = plt.cm.jet(np.linspace(0, 1, len(percentages)))\n",
    "    ax.pie(percentages, labels=percentages.index, autopct='%1.1f%%', \n",
    "           startangle=90, shadow=True, explode=[0.05] * len(percentages),\n",
    "           colors=colors)\n",
    "    ax.axis('equal')\n",
    "    ax.set_title(f'{column}', fontsize=14)\n",
    "\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    if column in preprocessed_df.columns and i < len(axes):\n",
    "        plot_pie_chart(preprocessed_df, column, axes[i], label_encoders)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Modeling for car price prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 Prepare train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into input and label data\n",
    "X = preprocessed_df.drop(columns = ['selling_price'])\n",
    "Y = preprocessed_df['selling_price']\n",
    "print(f'size of input data {X.shape}')\n",
    "print(f'size of input data {Y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.12, random_state = 42)\n",
    "print(f'x train size {x_train.shape}, x test size {x_test.shape}')\n",
    "print(f'y train size {y_train.shape}, y test size {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data (fit on train, transform on test)\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2 Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(), \n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'Random Forest': RandomForestRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "best_model = None\n",
    "best_model_name = None\n",
    "best_mse = float('inf')\n",
    "\n",
    "# Iterate over each model in the models dictionary\n",
    "for name, model in models.items():\n",
    "    # Fit the model on the scaled training data\n",
    "    model.fit(x_train_scaled, y_train)\n",
    "    \n",
    "    # Predict on training and testing datasets\n",
    "    train_pred = model.predict(x_train_scaled)\n",
    "    test_pred = model.predict(x_test_scaled)\n",
    "    \n",
    "    # Calculate evaluation metrics for training data\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    \n",
    "    # Calculate evaluation metrics for testing data\n",
    "    test_mse = mean_squared_error(y_test, test_pred)\n",
    "    test_mae = mean_absolute_error(y_test, test_pred)\n",
    "    \n",
    "    # Append all metrics to results list\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train MSE': train_mse,\n",
    "        'Test MSE': test_mse,\n",
    "        'Train MAE': train_mae,\n",
    "        'Test MAE': test_mae\n",
    "    })\n",
    "    \n",
    "    # Update the best model based on Test MSE\n",
    "    if test_mse < best_mse:\n",
    "        best_mse = test_mse\n",
    "        best_model = model\n",
    "        best_model_name = name\n",
    "\n",
    "# Create a DataFrame to display results\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3 Evaluate and choose the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metrics and their corresponding DataFrame columns\n",
    "metrics = [\n",
    "    ('MSE', 'Train MSE', 'Test MSE'),\n",
    "    ('MAE', 'Train MAE', 'Test MAE')\n",
    "]\n",
    "\n",
    "# Create subplots: one row per metric\n",
    "fig, axes = plt.subplots(nrows=len(metrics), ncols=1, figsize=(10, 18))\n",
    "\n",
    "# Loop over each metric to plot its bar chart\n",
    "for ax, (metric_name, train_col, test_col) in zip(axes, metrics):\n",
    "    # Set Model as index and select the current metric columns\n",
    "    df_plot = df_results.set_index('Model')[[train_col, test_col]]\n",
    "    \n",
    "    # Plot the bar chart for the current metric\n",
    "    df_plot.plot(kind='bar', ax=ax, rot=45, title=f\"{metric_name} Comparison\")\n",
    "    \n",
    "    # Add data labels on top of each bar\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='%.2f', padding=3)\n",
    "    \n",
    "    # Set the y-axis label\n",
    "    ax.set_ylabel(metric_name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model, \"best_model.pkl\")\n",
    "print(f\"Saved {best_model_name} to best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    sorted_idx = np.argsort(importances)[::-1]\n",
    "    sorted_importances = importances[sorted_idx]\n",
    "    sorted_features = feature_names[sorted_idx]\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(sorted_features, sorted_importances, color='skyblue')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(f\"Feature Importances - {best_model_name}\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"The model {best_model_name} does not have the 'feature_importances_' attribute\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "loaded_model = joblib.load(\"best_model.pkl\")\n",
    "\n",
    "# Predict\n",
    "predictions = loaded_model.predict(x_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, predictions, alpha=0.6)\n",
    "plt.xlabel(\"Actual Prices\")\n",
    "plt.ylabel(\"Predicted Prices\")\n",
    "plt.title(f\"Actual vs Predicted ({best_model_name})\")\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test.values, label=\"Actual\", marker='o', linestyle='dashed')\n",
    "plt.plot(predictions, label=\"Predicted\", marker='x', linestyle='dotted')\n",
    "plt.xlabel(\"Data Points\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title(f\"Actual vs Predicted Prices ({best_model_name})\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

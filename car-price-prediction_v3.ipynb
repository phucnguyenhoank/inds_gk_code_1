{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defind the correct order of columns\n",
    "correct_order = ['name', 'year', 'selling_price', 'km_driven', 'fuel', 'transmission', 'owner', 'mileage', 'engine', 'max_power', 'seats']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Giới thiệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vấn đề, tầm quan trọng, mục tiêu dự án."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giới thiệu tổng quan về dự án, tập trung vào việc dự đoán giá xe ở Ấn Độ và phân tích các yếu tố ảnh hưởng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trình bày vấn đề: Dự đoán giá xe dựa trên các thuộc tính như tuổi xe, loại nhiên liệu, km đã đi, v.v., và phân cụm để hiểu phân khúc thị trường.\n",
    "\n",
    "- Giải thích tầm quan trọng: Thị trường xe cũ ở Ấn Độ phát triển mạnh (khoảng 3,4 triệu xe giao dịch mỗi năm theo IJERT), ảnh hưởng bởi chính sách (BS-VI), và nhu cầu cá nhân hóa sau COVID-19.\n",
    "- Đặt mục tiêu: Xây dựng mô hình Random Forest để dự đoán giá xe chính xác.\n",
    "Sử dụng K-Means để phân cụm xe thành các nhóm (ví dụ: xe giá rẻ, xe cao cấp).\n",
    "Khám phá các yếu tố chính ảnh hưởng đến giá và phân khúc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hiểu dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mô tả: Nguồn dữ liệu, mô tả các thuộc tính, số lượng bản ghi.\n",
    "- Scope: Mô tả tập dữ liệu bạn đã có, đảm bảo phù hợp với thị trường Ấn Độ và đủ thông tin cho cả dự đoán giá và phân cụm.\n",
    "- Quy trình:\n",
    "    1. Nêu nguồn dữ liệu: Ví dụ, từ Kaggle, công ty ô tô, hoặc tự thu thập.\n",
    "    2. Mô tả các thuộc tính: Liệt kê tất cả cột (giá, nhãn hiệu, năm sản xuất, loại nhiên liệu, km đã đi, loại truyền động, v.v.) và ý nghĩa của chúng.\n",
    "    3. Thống kê cơ bản: Số lượng bản ghi (rows), số cột (columns), kiểu dữ liệu (numeric, categorical).\n",
    "- Công việc cụ thể:\n",
    "    - Dùng pandas trong Python để đọc dữ liệu (df.head(), df.info(), df.describe()).\n",
    "    - Ghi chú các đặc điểm ban đầu: Ví dụ, \"Dữ liệu gồm 10.000 xe, với giá từ 50.000 INR đến 5 triệu INR\".\n",
    "    - Kiểm tra xem dữ liệu có đại diện cho thị trường Ấn Độ không (nhiều nhãn hiệu như Maruti Suzuki, Hyundai không?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "raw_df1 = pd.read_csv('raw_csv/cardekho.csv')\n",
    "raw_df2 = pd.read_csv('raw_csv/train.csv')\n",
    "raw_df3 = pd.read_csv('raw_csv/processes2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hiển thị, mô tả các thuộc tính, số lượng bản ghi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_df1.shape)\n",
    "raw_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_df2.shape)\n",
    "raw_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_df3.shape)\n",
    "raw_df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Phân tích Khám phá Dữ liệu (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mô tả: Thống kê, biểu đồ, mối quan hệ giữa giá và các yếu tố.\n",
    "- Scope: Hiểu dữ liệu thô, phát hiện xu hướng, vấn đề (giá trị thiếu, ngoại lai), và chuẩn bị cho phân cụm K-Means.\n",
    "- Quy trình:\n",
    "    1. Thống kê mô tả: Tính trung bình, trung vị, độ lệch chuẩn của giá, tuổi xe, km đã đi.\n",
    "    2. Trực quan hóa:\n",
    "        -  Biểu đồ phân phối giá (histogram) để xem phân khúc giá phổ biến.\n",
    "        -  Biểu đồ phân tán (scatter plot) giữa giá và tuổi xe/km đã đi.\n",
    "        -  Biểu đồ hộp (box plot) để phát hiện ngoại lai (ví dụ: giá xe bất thường > 10 triệu INR).\n",
    "        -  Biểu đồ thanh (bar plot) để so sánh giá trung bình theo loại nhiên liệu/nhãn hiệu.\n",
    "    3. Phân tích mối quan hệ: Tính tương quan (correlation) giữa giá và các biến số (dùng df.corr()).\n",
    "- Công việc cụ thể:\n",
    "    - Sử dụng thư viện như matplotlib, seaborn để vẽ biểu đồ.\n",
    "    - Ghi nhận phát hiện: Ví dụ, \"Xe dầu diesel có giá trung bình cao hơn xe xăng 15%\".\n",
    "    - Chuẩn bị cho K-Means: Xem các biến như giá, km đã đi, tuổi xe có thể phân cụm xe thành các nhóm không."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dựa trên những thuộc tính đã khám phá từ 2., xử lý sơ bằng các chuyển kiểu dữ liệu về cho đúng để thuận tiện cho việc vẽ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuẩn hóa tên cột của tập dữ liệu, kiểu dữ liệu và đơn vị"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df1 = raw_df1[(raw_df1['fuel']!='CNG') & (raw_df1['fuel']!='LPG') & (raw_df1['owner']!='Test Drive Car')]\n",
    "raw_df1['owner'] = raw_df1['owner'].str.replace(' Owner','',regex=True)\n",
    "raw_df1['name'] = raw_df1['name'].str.split().str[0]# .str.title()\n",
    "raw_df1['selling_price'] = raw_df1['selling_price'] / 100000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary ánh xạ từ tên cột cũ sang tên cột mới\n",
    "column_mapping_df1 = {\n",
    "    \"mileage(km/ltr/kg)\": \"mileage\"\n",
    "}\n",
    "raw_df1 = raw_df1.drop(columns=['seller_type'])\n",
    "raw_df1.rename(columns=column_mapping_df1, inplace=True)\n",
    "print(raw_df1.columns)\n",
    "raw_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_df2['Owner_Type'].unique())\n",
    "raw_df2 = raw_df2[raw_df2['Fuel_Type']!='Electric']\n",
    "raw_df2['Engine'] = raw_df2['Engine'].str.extract('(\\d+)')  # Lấy chỉ số trong chuỗi\n",
    "raw_df2['Power'] = raw_df2['Power'].str.extract('(\\d+)')  # Lấy chỉ số trong chuỗi\n",
    "raw_df2['Mileage'] = raw_df2['Mileage'].str.extract('(\\d+)')  # Lấy chỉ số trong chuỗi\n",
    "raw_df2 = raw_df2[~raw_df2['Mileage'].str.contains('km/kg', na=False)]\n",
    "raw_df2['Name'] = raw_df2['Name'].str.split(' ').str[0]\n",
    "raw_df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_mapping_df2 = {\n",
    "        \"Year\": \"year\",\n",
    "        \"Kilometers_Driven\": \"km_driven\",\n",
    "        \"Fuel_Type\": \"fuel\",\n",
    "        \"Transmission\": \"transmission\",\n",
    "        \"Mileage\": \"mileage\",\n",
    "        \"Engine\": \"engine\",\n",
    "        \"Power\": \"max_power\",\n",
    "        \"Seats\": \"seats\",\n",
    "        \"Price\": \"selling_price\",\n",
    "        \"Name\": \"name\",\n",
    "        \"Owner_Type\": \"owner\"\n",
    "    }\n",
    "raw_df2 = raw_df2.drop(columns=['New_Price', 'Location','Unnamed: 0'])\n",
    "raw_df2.rename(columns=column_mapping_df2, inplace=True)\n",
    "raw_df2 = raw_df2[correct_order]\n",
    "raw_df2.info()\n",
    "raw_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu từ file csv\n",
    "raw_df3 = pd.read_csv('raw_csv/processes2.csv')\n",
    "raw_df3 = raw_df3[(raw_df3['fuel']!='CNG') & (raw_df3['fuel']!='LPG') & (raw_df3['owner']!='Test Drive Car')]\n",
    "raw_df3['owner'] = raw_df3['owner'].str.replace(' Owner','',regex=True)\n",
    "raw_df3['selling_price'] = raw_df3['selling_price'] / 100000.0\n",
    "print(raw_df3['fuel'].unique())\n",
    "print(raw_df3['owner'].unique())\n",
    "raw_df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping_df3 = {\n",
    "        \"max_power (in bph)\": \"max_power\",\n",
    "        \"Mileage\": \"mileage\",\n",
    "        \"Engine (CC)\": \"engine\"\n",
    "    }\n",
    "raw_df3 = raw_df3.drop(columns=['seller_type', 'Mileage Unit', 'Unnamed: 0'])\n",
    "raw_df3.rename(columns=column_mapping_df3, inplace=True)\n",
    "raw_df3 = raw_df3[correct_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(df, columns, figsize=(15, 12), bins_method='sqrt'):\n",
    "    \"\"\"\n",
    "    Vẽ histogram cho các cột liên tục trong DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame chứa dữ liệu.\n",
    "        columns (list): Danh sách tên các cột cần vẽ histogram.\n",
    "        figsize (tuple): Kích thước của figure (mặc định là (15, 12)).\n",
    "        bins_method (str): Phương pháp tính bin cho numpy.histogram_bin_edges() (mặc định là 'sqrt').\n",
    "\n",
    "    Returns:\n",
    "        None (Hiển thị biểu đồ).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    for index, col in enumerate(columns):\n",
    "        plt.subplot(2, 2, index + 1)\n",
    "        \n",
    "        # Chuyển cột về kiểu số, bỏ giá trị không hợp lệ\n",
    "        data = pd.to_numeric(df[col], errors='coerce').dropna()\n",
    "        \n",
    "        # Tính toán bin edges bằng phương pháp chỉ định\n",
    "        bin_edges = np.histogram_bin_edges(data, bins=bins_method)\n",
    "        num_bins = len(bin_edges) - 1  # Số bin thực tế\n",
    "        \n",
    "        # Vẽ histogram với số bin tính toán được\n",
    "        sns.histplot(data=data, bins=num_bins, color=sns.color_palette('pastel')[index], kde=True)\n",
    "        \n",
    "        plt.title(col.replace('_', ' ').capitalize(), fontsize=14, pad=10)\n",
    "        plt.xlabel(col.replace('_', ' ').capitalize(), fontsize=12)\n",
    "        plt.ylabel('Frequency', fontsize=12)\n",
    "        \n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tick_params(axis='both', labelsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_raw_columns = ['km_driven', 'mileage', 'engine', 'max_power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df1.info()\n",
    "raw_df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(raw_df1, continuous_raw_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df2.info()\n",
    "raw_df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(raw_df2, continuous_raw_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df3.info()\n",
    "raw_df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(raw_df3, continuous_raw_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 3 datasets\n",
    "merged_df = pd.concat([raw_df1, raw_df2, raw_df3], ignore_index=True)\n",
    "\n",
    "# Export to CSV file\n",
    "saved_file_path = 'raw_csv/merged_dataset.csv'\n",
    "merged_df.to_csv(saved_file_path, index=False)\n",
    "\n",
    "# Print message\n",
    "print(f\"Merged and saved to '{saved_file_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(saved_file_path)\n",
    "print(raw_df.shape)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.info()\n",
    "raw_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take copy from data to make processes on\n",
    "preprocessed_df = deepcopy(raw_df)\n",
    "\n",
    "# Show all types of columns in the data\n",
    "preprocessed_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check about none values in data to decide if we will make data cleaning or not\n",
    "preprocessed_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values of float columns that are mileage, engine, seats\n",
    "column_float_imputed = ['mileage', 'engine', 'max_power']\n",
    "preprocessed_df[column_float_imputed] = preprocessed_df[column_float_imputed].fillna(preprocessed_df[column_float_imputed].mean())\n",
    "\n",
    "# Handle missing values of seats column \n",
    "preprocessed_df['seats'] = preprocessed_df['seats'].fillna(preprocessed_df['seats'].mode()[0])\n",
    "\n",
    "# Check if there is any missing values in the dataset\n",
    "print(preprocessed_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling textual columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all textual columns in the dataset\n",
    "textual_columns = preprocessed_df.select_dtypes(include = ['object']).columns\n",
    "preprocessed_df[textual_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category columns\n",
    "categorical_columns = ['name', 'fuel', 'transmission', 'owner', 'seats', 'year']\n",
    "threshold = 5.0\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()  # Làm phẳng mảng axes để dễ dàng lặp qua\n",
    "\n",
    "def plot_pie_chart(df, column, ax):\n",
    "\n",
    "    value_counts = df[column].value_counts()\n",
    "    percentages = value_counts / value_counts.sum() * 100\n",
    "    \n",
    "    mask = percentages < threshold\n",
    "    if mask.any():\n",
    "        other_percentage = percentages[mask].sum()\n",
    "        percentages = percentages[~mask]\n",
    "        percentages['Other'] = other_percentage\n",
    "    \n",
    "    colors = plt.cm.jet(np.linspace(0, 1, len(percentages)))\n",
    "    ax.pie(percentages, labels=percentages.index, autopct='%1.1f%%', \n",
    "           startangle=90, shadow=True, explode=[0.05] * len(percentages),\n",
    "           colors=colors)\n",
    "    ax.axis('equal')\n",
    "    ax.set_title(f'{column}', fontsize=14)\n",
    "\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    if column in preprocessed_df.columns and i < len(axes):\n",
    "        plot_pie_chart(preprocessed_df, column, axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(preprocessed_df, continuous_raw_columns)\n",
    "\n",
    "# # Define continuos columns\n",
    "# continuous_columns = ['km_driven', 'mileage', 'engine', 'max_power']\n",
    "\n",
    "# plt.figure(figsize=(15, 12))\n",
    "\n",
    "# for index, col in enumerate(continuous_columns):\n",
    "#     plt.subplot(2, 2, index + 1)\n",
    "    \n",
    "#     sns.histplot(data=preprocessed_df[col], bins=50, \n",
    "#                  color=sns.color_palette('pastel')[index], kde=True)\n",
    "    \n",
    "#     plt.title(col.replace('_', ' ').capitalize(), fontsize=14, pad=10)\n",
    "    \n",
    "#     plt.xlabel(col.replace('_', ' ').capitalize(), fontsize=12)\n",
    "#     plt.ylabel('Frequency', fontsize=12)\n",
    "    \n",
    "#     plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "#     plt.tick_params(axis='both', labelsize=10)\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding textual columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the encoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Fit and transform each textual column, saving the encoders\n",
    "for col in textual_columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    preprocessed_df[col] = label_encoder.fit_transform(preprocessed_df[col])\n",
    "    label_encoders[col] = label_encoder\n",
    "\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check about if there is any extra textual columns\n",
    "preprocessed_df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = preprocessed_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='Blues', \n",
    "            annot_kws={\"size\": 10}, linewidths=0.5, fmt=\".2f\")\n",
    "plt.title('Correlation Matrix', fontsize=20)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the selling_price \n",
    "corr_with_price = correlation_matrix['selling_price'].drop('selling_price').sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=corr_with_price.index, y=corr_with_price.values, \n",
    "            hue=corr_with_price.index, palette='Blues_d')\n",
    "\n",
    "plt.title('Correlation of Features with Selling Price', fontsize=16, pad=20)\n",
    "\n",
    "plt.xlabel('Features', fontsize=12)\n",
    "plt.ylabel('Correlation Coefficient', fontsize=12)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove selling_price column\n",
    "column_skewed = preprocessed_df.columns.drop('selling_price')\n",
    "\n",
    "# Compute skewness for each column\n",
    "skewness = preprocessed_df.drop(columns=['selling_price']).skew()\n",
    "print(skewness)\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "sns.barplot(x=column_skewed, y=skewness, hue=column_skewed, palette='coolwarm')\n",
    "\n",
    "plt.title('Skewness of Features in Car Dataset', fontsize=16, pad=20)\n",
    "\n",
    "plt.xlabel('Features', fontsize=12)\n",
    "plt.ylabel('Skewness', fontsize=12)\n",
    "\n",
    "plt.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle skewness of km driven columns by taking the log function for it\n",
    "preprocessed_df['km_driven'] = np.log(preprocessed_df['km_driven'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find skewness for km driven column after we handled it\n",
    "preprocessed_df['km_driven'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove selling_price column\n",
    "column_skewed = preprocessed_df.columns.drop('selling_price')\n",
    "\n",
    "# Compute skewness for each column\n",
    "skewness = preprocessed_df.drop(columns=['selling_price']).skew()\n",
    "print(skewness)\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "sns.barplot(x=column_skewed, y=skewness, hue=column_skewed, palette='coolwarm')\n",
    "\n",
    "plt.title('Skewness of Features in Car Dataset', fontsize=16, pad=20)\n",
    "\n",
    "plt.xlabel('Features', fontsize=12)\n",
    "plt.ylabel('Skewness', fontsize=12)\n",
    "\n",
    "plt.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the preprocessed data and label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Đường dẫn thư mục lưu dữ liệu\n",
    "processed_data_dir = \"processed_data\"\n",
    "saved_processed_data_path = os.path.join(processed_data_dir, \"preprocessed_dataset.csv\")\n",
    "saved_label_encoders_path = os.path.join(processed_data_dir, \"label_encoders.sav\")\n",
    "\n",
    "# Tạo thư mục nếu chưa tồn tại\n",
    "os.makedirs(processed_data_dir, exist_ok=True)\n",
    "\n",
    "# Ghi DataFrame ra CSV\n",
    "preprocessed_df.to_csv(saved_processed_data_path, index=False)\n",
    "\n",
    "# Lưu label encoders\n",
    "joblib.dump(label_encoders, saved_label_encoders_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.read_csv(saved_processed_data_path)\n",
    "threshold = 3  # Giá trị ngưỡng để so sánh\n",
    "\n",
    "# Đếm số lượng giá trị bằng 0 theo từng cột\n",
    "zero_counts = (df_temp == 0).sum()\n",
    "\n",
    "# Đếm số lượng giá trị nhỏ hơn ngưỡng threshold theo từng cột\n",
    "below_threshold_counts = (df_temp < threshold).sum()\n",
    "\n",
    "# Hiển thị kết quả\n",
    "print(\"Count of zero values per column:\\n\", zero_counts)\n",
    "print(\"\\nCount of values below threshold per column:\\n\", below_threshold_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Drop non-numeric columns (if necessary)\n",
    "df_numeric = preprocessed_df.drop(columns=[\"name\"])  # 'name' is a categorical feature\n",
    "\n",
    "# Feature scaling (K-Means is sensitive to different scales)\n",
    "cluestering_scaler = StandardScaler()\n",
    "df_scaled = cluestering_scaler.fit_transform(df_numeric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the optimal K using the Elbow method\n",
    "inertia = []\n",
    "K_range = range(1, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(df_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow method result\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, inertia, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method to Determine Optimal K')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the optimal K (e.g., based on the elbow method)\n",
    "optimal_k = 3  # Change this based on the elbow plot\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df_numeric[\"Cluster\"] = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "# Add cluster labels to original dataframe\n",
    "preprocessed_df[\"Cluster\"] = df_numeric[\"Cluster\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=preprocessed_df[\"mileage\"], y=preprocessed_df[\"selling_price\"], hue=preprocessed_df[\"Cluster\"], palette=\"viridis\", s=80)\n",
    "plt.xlabel(\"Mileage (km/l)\")\n",
    "plt.ylabel(\"Selling Price (Lakhs)\")\n",
    "plt.title(f\"K-Means Clustering with {optimal_k} Clusters\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average values for each cluster\n",
    "cluster_summary = df_numeric.groupby(\"Cluster\").mean()\n",
    "cluster_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "preprocessed_df = pd.read_csv(saved_processed_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into input and label data\n",
    "X = preprocessed_df.drop(columns = ['selling_price'])\n",
    "Y = preprocessed_df['selling_price']\n",
    "print(f'size of input data {X.shape}')\n",
    "print(f'size of input data {Y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.12, random_state = 42)\n",
    "print(f'x train size {x_train.shape}, x test size {x_test.shape}')\n",
    "print(f'y train size {y_train.shape}, y test size {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data (fit on train, transform on test)\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(), \n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(), \n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'Random Forest': RandomForestRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "best_model = None\n",
    "best_model_name = None\n",
    "best_mse = float('inf')\n",
    "\n",
    "# Iterate over each model in the models dictionary\n",
    "for name, model in models.items():\n",
    "    # Fit the model on the scaled training data\n",
    "    model.fit(x_train_scaled, y_train)\n",
    "    \n",
    "    # Predict on training and testing datasets\n",
    "    train_pred = model.predict(x_train_scaled)\n",
    "    test_pred = model.predict(x_test_scaled)\n",
    "    \n",
    "    # Calculate evaluation metrics for training data\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    \n",
    "    # Calculate evaluation metrics for testing data\n",
    "    test_mse = mean_squared_error(y_test, test_pred)\n",
    "    test_mae = mean_absolute_error(y_test, test_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    \n",
    "    # Append all metrics to results list\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train MSE': train_mse,\n",
    "        'Test MSE': test_mse,\n",
    "        'Train MAE': train_mae,\n",
    "        'Test MAE': test_mae,\n",
    "        'Train R^2': train_r2,\n",
    "        'Test R^2': test_r2\n",
    "    })\n",
    "    \n",
    "    # Update the best model based on Test MSE\n",
    "    if test_mse < best_mse:\n",
    "        best_mse = test_mse\n",
    "        best_model = model\n",
    "        best_model_name = name\n",
    "\n",
    "# Create a DataFrame to display results\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metrics and their corresponding DataFrame columns\n",
    "metrics = [\n",
    "    ('MSE', 'Train MSE', 'Test MSE'),\n",
    "    ('MAE', 'Train MAE', 'Test MAE'),\n",
    "    ('R^2', 'Train R^2', 'Test R^2')\n",
    "]\n",
    "\n",
    "# Create subplots: one row per metric\n",
    "fig, axes = plt.subplots(nrows=len(metrics), ncols=1, figsize=(10, 18))\n",
    "\n",
    "# Loop over each metric to plot its bar chart\n",
    "for ax, (metric_name, train_col, test_col) in zip(axes, metrics):\n",
    "    # Set Model as index and select the current metric columns\n",
    "    df_plot = df_results.set_index('Model')[[train_col, test_col]]\n",
    "    \n",
    "    # Plot the bar chart for the current metric\n",
    "    df_plot.plot(kind='bar', ax=ax, rot=45, title=f\"{metric_name} Comparison\")\n",
    "    \n",
    "    # Add data labels on top of each bar\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='%.2f', padding=3)\n",
    "    \n",
    "    # Set the y-axis label\n",
    "    ax.set_ylabel(metric_name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model, \"best_model.pkl\")\n",
    "print(f\"Saved {best_model_name} to best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Sắp xếp giảm dần theo độ quan trọng\n",
    "    sorted_idx = np.argsort(importances)[::-1]\n",
    "    sorted_importances = importances[sorted_idx]\n",
    "    sorted_features = feature_names[sorted_idx]\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(sorted_features, sorted_importances, color='skyblue')\n",
    "    plt.gca().invert_yaxis()  # Để feature cao nhất ở trên cùng\n",
    "    plt.title(f\"Feature Importances - {best_model_name}\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"The model {best_model_name} does not have the 'feature_importances_' attribute\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "loaded_model = joblib.load(\"best_model.pkl\")\n",
    "\n",
    "# Predict\n",
    "predictions = loaded_model.predict(x_test_scaled)\n",
    "\n",
    "zero_count = np.sum(x_test_scaled == 0)\n",
    "zero_count_2 = np.sum(predictions == 0)\n",
    "zero_count_3 = (y_test < 3).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zero_count_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, predictions, alpha=0.6)\n",
    "plt.xlabel(\"Actual Prices\")\n",
    "plt.ylabel(\"Predicted Prices\")\n",
    "plt.title(f\"Actual vs Predicted ({best_model_name})\")\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold\n",
    "y_threshold = max(y_test) / 3\n",
    "\n",
    "mask = y_test <= y_threshold\n",
    "filtered_y_test = y_test[mask]\n",
    "filtered_predictions = predictions[mask]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(filtered_y_test, filtered_predictions, alpha=0.6)\n",
    "plt.xlabel(\"Actual Prices\")\n",
    "plt.ylabel(\"Predicted Prices\")\n",
    "plt.title(f\"Actual vs Predicted (Filtered) - {best_model_name}\")\n",
    "plt.plot([min(filtered_y_test), max(filtered_y_test)], \n",
    "         [min(filtered_y_test), max(filtered_y_test)], color='red')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test.values, label=\"Actual\", marker='o', linestyle='dashed')\n",
    "plt.plot(predictions, label=\"Predicted\", marker='x', linestyle='dotted')\n",
    "plt.xlabel(\"Data Points\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title(f\"Actual vs Predicted Prices ({best_model_name})\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
